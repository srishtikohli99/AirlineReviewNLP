{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "with open('glove.6B.50d.txt',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:],dtype='float32')\n",
    "        \n",
    "        #print(word)\n",
    "        #print(coeffs)\n",
    "        embeddings[word] = coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srishti/anaconda3/envs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3051: DtypeWarning: Columns (6,7,12,13,14,15,16,17,18) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"combined.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>airline</th>\n",
       "      <th>date_published</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date_flown</th>\n",
       "      <th>rating</th>\n",
       "      <th>verified_user</th>\n",
       "      <th>route</th>\n",
       "      <th>aircraft</th>\n",
       "      <th>traveller_type</th>\n",
       "      <th>cabin_flown</th>\n",
       "      <th>seat_comfort</th>\n",
       "      <th>cabin_staff_service</th>\n",
       "      <th>food_beverages</th>\n",
       "      <th>ground_service</th>\n",
       "      <th>inflight_entertainment</th>\n",
       "      <th>value_for_money</th>\n",
       "      <th>wifi_and_connectivity</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>adria-airways</td>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>\"should be ashamed of their operations\"</td>\n",
       "      <td>|  Ljubljana to Vienna. Overall, the flight s...</td>\n",
       "      <td>September 2017</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Ljubljana to Vienna</td>\n",
       "      <td>ATR-72</td>\n",
       "      <td>Solo Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>adria-airways</td>\n",
       "      <td>2017-11-20</td>\n",
       "      <td>\"Two nice short flights\"</td>\n",
       "      <td>| Two nice short flights from Ljubljana to Sa...</td>\n",
       "      <td>November 2017</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>Ljubljana to Sarajevo</td>\n",
       "      <td>CRJ700 / ATR72</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>adria-airways</td>\n",
       "      <td>2017-10-27</td>\n",
       "      <td>\"extremely bad service\"</td>\n",
       "      <td>| We were 11 people coming in with a short co...</td>\n",
       "      <td>October 2017</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>Zurich to Ljubjana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Couple Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>adria-airways</td>\n",
       "      <td>2017-09-16</td>\n",
       "      <td>\"never fly this airline again\"</td>\n",
       "      <td>|  Ljubljana to Munich after arriving from At...</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>Ljubljana to Munich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Family Leisure</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>adria-airways</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>\"can't remember a flight delay\"</td>\n",
       "      <td>| Ljubljana to Zurich on April 18th. Adria Ai...</td>\n",
       "      <td>April 2017</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>Ljubljana to Zurich</td>\n",
       "      <td>CR9</td>\n",
       "      <td>Business</td>\n",
       "      <td>Economy Class</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        airline date_published  \\\n",
       "0           1  adria-airways     2017-12-05   \n",
       "1           2  adria-airways     2017-11-20   \n",
       "2           3  adria-airways     2017-10-27   \n",
       "3           4  adria-airways     2017-09-16   \n",
       "4           5  adria-airways     2017-04-19   \n",
       "\n",
       "                                     title  \\\n",
       "0  \"should be ashamed of their operations\"   \n",
       "1                 \"Two nice short flights\"   \n",
       "2                  \"extremely bad service\"   \n",
       "3           \"never fly this airline again\"   \n",
       "4          \"can't remember a flight delay\"   \n",
       "\n",
       "                                                text      date_flown rating  \\\n",
       "0   |  Ljubljana to Vienna. Overall, the flight s...  September 2017      3   \n",
       "1   | Two nice short flights from Ljubljana to Sa...   November 2017      9   \n",
       "2   | We were 11 people coming in with a short co...    October 2017      2   \n",
       "3   |  Ljubljana to Munich after arriving from At...       June 2017      2   \n",
       "4   | Ljubljana to Zurich on April 18th. Adria Ai...      April 2017      9   \n",
       "\n",
       "  verified_user                  route        aircraft  traveller_type  \\\n",
       "0          True    Ljubljana to Vienna          ATR-72    Solo Leisure   \n",
       "1          True  Ljubljana to Sarajevo  CRJ700 / ATR72        Business   \n",
       "2          True     Zurich to Ljubjana             NaN  Couple Leisure   \n",
       "3          True   Ljubljana to Munich              NaN  Family Leisure   \n",
       "4          True    Ljubljana to Zurich             CR9        Business   \n",
       "\n",
       "     cabin_flown seat_comfort cabin_staff_service food_beverages  \\\n",
       "0  Economy Class            2                   4              1   \n",
       "1  Economy Class            5                   5              3   \n",
       "2  Economy Class            3                   3            NaN   \n",
       "3  Economy Class            3                   4              1   \n",
       "4  Economy Class            5                   5              4   \n",
       "\n",
       "  ground_service inflight_entertainment value_for_money wifi_and_connectivity  \\\n",
       "0              1                    NaN               3                   NaN   \n",
       "1              5                    NaN               3                   NaN   \n",
       "2              1                    NaN               1                   NaN   \n",
       "3              1                    NaN               2                     1   \n",
       "4              5                      4               4                   NaN   \n",
       "\n",
       "  recommended  \n",
       "0          no  \n",
       "1         yes  \n",
       "2          no  \n",
       "3          no  \n",
       "4         yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['text','recommended']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>recommended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>|  Ljubljana to Vienna. Overall, the flight s...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>| Two nice short flights from Ljubljana to Sa...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>| We were 11 people coming in with a short co...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>|  Ljubljana to Munich after arriving from At...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>| Ljubljana to Zurich on April 18th. Adria Ai...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text recommended\n",
       "0   |  Ljubljana to Vienna. Overall, the flight s...          no\n",
       "1   | Two nice short flights from Ljubljana to Sa...         yes\n",
       "2   | We were 11 people coming in with a short co...          no\n",
       "3   |  Ljubljana to Munich after arriving from At...          no\n",
       "4   | Ljubljana to Zurich on April 18th. Adria Ai...         yes"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70284 entries, 0 to 70283\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   text         70284 non-null  object\n",
      " 1   recommended  70284 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70284 entries, 0 to 70283\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   text         70284 non-null  object\n",
      " 1   recommended  70284 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data =df\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop  = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# types = []\n",
    "# for i in range(data.shape[0]):\n",
    "#     #print(type(data['text'][i]))\n",
    "#     #np.append(types,type(data['text'][i]))\n",
    "#     types.append(type(data['text'][i]))\n",
    "#     #if isinstance(data['text'][i], !str):\n",
    "#         #print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(data.index[51469])\n",
    "#data['text'][51469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(types)):\n",
    "#     if types[i]=='str':\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5001\n",
      "10001\n",
      "15001\n",
      "20001\n",
      "25001\n",
      "30001\n",
      "35001\n",
      "40001\n",
      "45001\n",
      "50001\n",
      "55001\n",
      "60001\n",
      "65001\n",
      "70001\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,70284,1):\n",
    "    if i%5000 == 1:\n",
    "        print(i)\n",
    "    words =  nltk.word_tokenize(data['text'][i])\n",
    "    words = [w.lower() for w in words if len(w)>2 and w not in stop]\n",
    "    data['text'][i] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim\n",
    "# from gensim.models import word2vec\n",
    "# from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(data['text'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n"
     ]
    }
   ],
   "source": [
    "for i in range(70284):\n",
    "    if i%5000 == 0:\n",
    "        print(i)\n",
    "    words = data['text'][i]\n",
    "    wv = []\n",
    "    for w in words:\n",
    "        w = lemmatizer.lemmatize(w)\n",
    "        if embeddings.get(w) is None:\n",
    "            continue\n",
    "        wvec = embeddings[w]\n",
    "        wv.append(wvec)\n",
    "    if len(wv) == 0:\n",
    "        data['text'][i] = None\n",
    "        \n",
    "    else:\n",
    "        data['text'][i] = wv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5168\n",
      "12223\n",
      "12224\n",
      "20094\n",
      "20095\n",
      "22016\n",
      "23093\n",
      "27491\n",
      "27493\n",
      "28896\n",
      "29190\n",
      "30801\n",
      "31523\n",
      "34302\n",
      "40006\n",
      "40914\n",
      "41983\n",
      "42880\n",
      "48968\n",
      "49486\n",
      "50888\n",
      "51322\n",
      "59733\n",
      "62355\n",
      "63976\n"
     ]
    }
   ],
   "source": [
    "sizes=[]\n",
    "for i in range(70284):\n",
    "    if data['text'][i] is None:\n",
    "        print(i)\n",
    "        continue\n",
    "    sizes.append(len(data['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70284 entries, 0 to 70283\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   text         70259 non-null  object\n",
      " 1   recommended  70284 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70259 entries, 0 to 70258\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   text         70259 non-null  object\n",
      " 1   recommended  70259 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([195,  70,  40, ...,  18,  15,  78])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[0:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.iloc[0:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('dataX.npy', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(np.array(sizes),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1    5]\n",
      " [   5    1]\n",
      " [   6    2]\n",
      " [   7    7]\n",
      " [   8   10]\n",
      " [   9   37]\n",
      " [  10   57]\n",
      " [  11   83]\n",
      " [  12  122]\n",
      " [  13  165]\n",
      " [  14  203]\n",
      " [  15  242]\n",
      " [  16  264]\n",
      " [  17  312]\n",
      " [  18  356]\n",
      " [  19  412]\n",
      " [  20  435]\n",
      " [  21  531]\n",
      " [  22  539]\n",
      " [  23  637]\n",
      " [  24  712]\n",
      " [  25  733]\n",
      " [  26  824]\n",
      " [  27  894]\n",
      " [  28  878]\n",
      " [  29  952]\n",
      " [  30 1046]\n",
      " [  31 1080]\n",
      " [  32 1002]\n",
      " [  33 1090]\n",
      " [  34 1109]\n",
      " [  35 1005]\n",
      " [  36 1066]\n",
      " [  37 1076]\n",
      " [  38  990]\n",
      " [  39 1016]\n",
      " [  40 1038]\n",
      " [  41 1089]\n",
      " [  42 1112]\n",
      " [  43 1031]\n",
      " [  44 1059]\n",
      " [  45  994]\n",
      " [  46 1016]\n",
      " [  47  965]\n",
      " [  48 1000]\n",
      " [  49  989]\n",
      " [  50  946]\n",
      " [  51  910]\n",
      " [  52  876]\n",
      " [  53  874]\n",
      " [  54  890]\n",
      " [  55  910]\n",
      " [  56  814]\n",
      " [  57  795]\n",
      " [  58  824]\n",
      " [  59  840]\n",
      " [  60  761]\n",
      " [  61  762]\n",
      " [  62  766]\n",
      " [  63  728]\n",
      " [  64  711]\n",
      " [  65  718]\n",
      " [  66  771]\n",
      " [  67  689]\n",
      " [  68  664]\n",
      " [  69  693]\n",
      " [  70  654]\n",
      " [  71  635]\n",
      " [  72  615]\n",
      " [  73  574]\n",
      " [  74  532]\n",
      " [  75  590]\n",
      " [  76  527]\n",
      " [  77  496]\n",
      " [  78  503]\n",
      " [  79  469]\n",
      " [  80  445]\n",
      " [  81  427]\n",
      " [  82  464]\n",
      " [  83  440]\n",
      " [  84  448]\n",
      " [  85  398]\n",
      " [  86  394]\n",
      " [  87  357]\n",
      " [  88  432]\n",
      " [  89  387]\n",
      " [  90  351]\n",
      " [  91  340]\n",
      " [  92  348]\n",
      " [  93  340]\n",
      " [  94  327]\n",
      " [  95  312]\n",
      " [  96  282]\n",
      " [  97  289]\n",
      " [  98  295]\n",
      " [  99  270]\n",
      " [ 100  282]\n",
      " [ 101  298]\n",
      " [ 102  264]\n",
      " [ 103  274]\n",
      " [ 104  261]\n",
      " [ 105  244]\n",
      " [ 106  265]\n",
      " [ 107  225]\n",
      " [ 108  193]\n",
      " [ 109  201]\n",
      " [ 110  233]\n",
      " [ 111  196]\n",
      " [ 112  187]\n",
      " [ 113  204]\n",
      " [ 114  182]\n",
      " [ 115  197]\n",
      " [ 116  158]\n",
      " [ 117  170]\n",
      " [ 118  165]\n",
      " [ 119  144]\n",
      " [ 120  161]\n",
      " [ 121  169]\n",
      " [ 122  172]\n",
      " [ 123  152]\n",
      " [ 124  130]\n",
      " [ 125  111]\n",
      " [ 126  146]\n",
      " [ 127  124]\n",
      " [ 128  124]\n",
      " [ 129  108]\n",
      " [ 130  143]\n",
      " [ 131  102]\n",
      " [ 132  111]\n",
      " [ 133  117]\n",
      " [ 134  108]\n",
      " [ 135  103]\n",
      " [ 136   99]\n",
      " [ 137  100]\n",
      " [ 138  110]\n",
      " [ 139  106]\n",
      " [ 140  113]\n",
      " [ 141  109]\n",
      " [ 142  100]\n",
      " [ 143   91]\n",
      " [ 144   90]\n",
      " [ 145   87]\n",
      " [ 146   82]\n",
      " [ 147   90]\n",
      " [ 148   77]\n",
      " [ 149   76]\n",
      " [ 150   82]\n",
      " [ 151   80]\n",
      " [ 152   75]\n",
      " [ 153   68]\n",
      " [ 154   72]\n",
      " [ 155   74]\n",
      " [ 156   79]\n",
      " [ 157   58]\n",
      " [ 158   59]\n",
      " [ 159   66]\n",
      " [ 160   61]\n",
      " [ 161   54]\n",
      " [ 162   63]\n",
      " [ 163   47]\n",
      " [ 164   46]\n",
      " [ 165   49]\n",
      " [ 166   58]\n",
      " [ 167   40]\n",
      " [ 168   44]\n",
      " [ 169   41]\n",
      " [ 170   45]\n",
      " [ 171   44]\n",
      " [ 172   50]\n",
      " [ 173   61]\n",
      " [ 174   47]\n",
      " [ 175   46]\n",
      " [ 176   40]\n",
      " [ 177   40]\n",
      " [ 178   38]\n",
      " [ 179   56]\n",
      " [ 180   36]\n",
      " [ 181   35]\n",
      " [ 182   34]\n",
      " [ 183   35]\n",
      " [ 184   39]\n",
      " [ 185   40]\n",
      " [ 186   32]\n",
      " [ 187   32]\n",
      " [ 188   21]\n",
      " [ 189   30]\n",
      " [ 190   38]\n",
      " [ 191   22]\n",
      " [ 192   28]\n",
      " [ 193   32]\n",
      " [ 194   26]\n",
      " [ 195   23]\n",
      " [ 196   31]\n",
      " [ 197   18]\n",
      " [ 198   26]\n",
      " [ 199   25]\n",
      " [ 200   18]\n",
      " [ 201   17]\n",
      " [ 202   26]\n",
      " [ 203   19]\n",
      " [ 204   19]\n",
      " [ 205   23]\n",
      " [ 206   22]\n",
      " [ 207   15]\n",
      " [ 208   15]\n",
      " [ 209   15]\n",
      " [ 210   11]\n",
      " [ 211   17]\n",
      " [ 212   24]\n",
      " [ 213   17]\n",
      " [ 214   12]\n",
      " [ 215   23]\n",
      " [ 216   14]\n",
      " [ 217   19]\n",
      " [ 218   15]\n",
      " [ 219   18]\n",
      " [ 220   18]\n",
      " [ 221   16]\n",
      " [ 222   19]\n",
      " [ 223   19]\n",
      " [ 224   13]\n",
      " [ 225   17]\n",
      " [ 226   23]\n",
      " [ 227    9]\n",
      " [ 228   10]\n",
      " [ 229   13]\n",
      " [ 230   15]\n",
      " [ 231   13]\n",
      " [ 232    6]\n",
      " [ 233    9]\n",
      " [ 234   14]\n",
      " [ 235   13]\n",
      " [ 236   10]\n",
      " [ 237   12]\n",
      " [ 238   12]\n",
      " [ 239   11]\n",
      " [ 240   10]\n",
      " [ 241    9]\n",
      " [ 242    5]\n",
      " [ 243    5]\n",
      " [ 244   10]\n",
      " [ 245   10]\n",
      " [ 246   10]\n",
      " [ 247    9]\n",
      " [ 248   14]\n",
      " [ 249   11]\n",
      " [ 250   15]\n",
      " [ 251   11]\n",
      " [ 252    7]\n",
      " [ 253    9]\n",
      " [ 254   11]\n",
      " [ 255   12]\n",
      " [ 256   13]\n",
      " [ 257    8]\n",
      " [ 258   14]\n",
      " [ 259    7]\n",
      " [ 260    6]\n",
      " [ 261   11]\n",
      " [ 262    6]\n",
      " [ 263    1]\n",
      " [ 264    7]\n",
      " [ 265   10]\n",
      " [ 266    9]\n",
      " [ 267    6]\n",
      " [ 268    2]\n",
      " [ 269    4]\n",
      " [ 270    6]\n",
      " [ 271   11]\n",
      " [ 272    4]\n",
      " [ 273   12]\n",
      " [ 274    8]\n",
      " [ 275    2]\n",
      " [ 276    6]\n",
      " [ 277    6]\n",
      " [ 278    8]\n",
      " [ 279    6]\n",
      " [ 280    5]\n",
      " [ 281    9]\n",
      " [ 282    5]\n",
      " [ 283    5]\n",
      " [ 284    2]\n",
      " [ 285    8]\n",
      " [ 286    4]\n",
      " [ 287   10]\n",
      " [ 288   10]\n",
      " [ 289    2]\n",
      " [ 290    6]\n",
      " [ 291    7]\n",
      " [ 292    5]\n",
      " [ 293    5]\n",
      " [ 294    3]\n",
      " [ 295    3]\n",
      " [ 296    7]\n",
      " [ 297   10]\n",
      " [ 298    2]\n",
      " [ 299    3]\n",
      " [ 300    4]\n",
      " [ 301    5]\n",
      " [ 302    2]\n",
      " [ 303    1]\n",
      " [ 304    3]\n",
      " [ 305    5]\n",
      " [ 306    4]\n",
      " [ 307    3]\n",
      " [ 308    2]\n",
      " [ 309    1]\n",
      " [ 310    2]\n",
      " [ 311    6]\n",
      " [ 312    5]\n",
      " [ 313    4]\n",
      " [ 314    1]\n",
      " [ 315    3]\n",
      " [ 316    2]\n",
      " [ 317    3]\n",
      " [ 318    3]\n",
      " [ 319    1]\n",
      " [ 324    2]\n",
      " [ 325    2]\n",
      " [ 327    3]\n",
      " [ 329    1]\n",
      " [ 331    1]\n",
      " [ 335    1]\n",
      " [ 343    1]\n",
      " [ 345    1]\n",
      " [ 348    2]\n",
      " [ 349    1]\n",
      " [ 427    1]\n",
      " [ 460    1]]\n"
     ]
    }
   ],
   "source": [
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/srishti/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = keras.preprocessing.sequence.pad_sequences(X, maxlen=200, padding='post',truncating = 'post',dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"DataGloveY.npy\",Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 10, 64)            93440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 126,789\n",
      "Trainable params: 126,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add\n",
    "model.add(LSTM(64,input_shape=(10,300),return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(64,input_shape=(10,300)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
